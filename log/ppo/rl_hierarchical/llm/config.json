{
    "ask_lambda": 0.01,
    "batch_size": 64,
    "device": "cuda",
    "episode": "21",
    "eval_type": "LLM",
    "evals_per_ep": 1,
    "gamma": 0.99,
    "lam": 0.95,
    "n_itr": 1000,
    "num_environments": 1,
    "policy": "ppo",
    "record_video": false,
    "save_name": "llm",
    "seed": null,
    "task": "rl_hierarchical",
    "test_num": 10,
    "traj_per_itr": 10
}